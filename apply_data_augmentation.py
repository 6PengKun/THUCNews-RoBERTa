"""
THUCNewsæ•°æ®é›†çš„GPUåŠ é€Ÿæ•°æ®å¢å¼ºå·¥å…·

ç‰¹ç‚¹ï¼š
1. åªå¯¹å°ç±»åˆ«è¿›è¡Œå¢å¼ºï¼Œæ§åˆ¶æ€»æ•°æ®é‡
2. ä½¿ç”¨GPUåŠ é€Ÿç¿»è¯‘æ¨¡å‹
3. æ‰¹å¤„ç†æé«˜GPUåˆ©ç”¨ç‡
4. æ”¯æŒå¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†EDAæ–¹æ³•
5. å¢å¼ºçš„è¿›åº¦æ¡æ˜¾ç¤ºï¼Œæ›´ç›´è§‚åœ°å±•ç¤ºå¤„ç†è¿›åº¦
"""
import os
import sys
import time
import random
import jieba
import torch
import numpy as np
from tqdm import tqdm
import multiprocessing
from collections import Counter, defaultdict

# è®¾ç½®ç¯å¢ƒå˜é‡ä»¥ä½¿ç”¨é•œåƒç«™ç‚¹ï¼ˆå¦‚éœ€è¦ï¼‰
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# ä¸­æ–‡åœç”¨è¯åˆ—è¡¨
STOPWORDS = set(['çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±',
                'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ',
                'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰',
                'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™', 'ç€', 'é‚£', 'è€Œ', 'ä¸',
                'å¯¹', 'ä¹‹', 'ä¸', 'è¢«', 'å®ƒ', 'ä¸º', 'æ‰€', 'å¦‚'])

# åŸºäºç±»åˆ«çš„ä¿å®ˆå¢å¼ºæ¯”ä¾‹é…ç½®ï¼ˆå‡å°‘æ•°æ®é‡ï¼‰
DEFAULT_ENHANCEMENT_RATIOS = {
    "ç§‘æŠ€": 0.01,   # æ•°æ®æœ€å¤šï¼Œä¸å¢å¼º
    "ä½“è‚²": 0.01,   # æ•°æ®å……è¶³ï¼Œä¸å¢å¼º
    "è‚¡ç¥¨": 0.01,   # æ•°æ®å……è¶³ï¼Œä¸å¢å¼º
    "å¨±ä¹": 0.01,   # æ•°æ®å……è¶³ï¼Œä¸å¢å¼º
    "æ—¶æ”¿": 0.2,   # è½»åº¦å¢å¼º
    "ç¤¾ä¼š": 0.2,   # è½»åº¦å¢å¼º
    "æ•™è‚²": 0.3,   # ä¸­åº¦å¢å¼º
    "è´¢ç»": 0.4,   # ä¸­åº¦å¢å¼º
    "å®¶å±…": 0.5,   # ä¸­åº¦å¢å¼º
    "æ¸¸æˆ": 0.6,   # è¾ƒå¤šå¢å¼º
    "æˆ¿äº§": 0.8,   # è¾ƒå¤šå¢å¼º
    "æ—¶å°š": 1.0,   # è¾ƒå¤šå¢å¼º
    "å½©ç¥¨": 1.5,   # å¤§é‡å¢å¼º
    "æ˜Ÿåº§": 2.0    # å¤§é‡å¢å¼ºï¼Œä½†æ¯”åŸæ–¹æ¡ˆå°‘
}

# æœ€å¤§å¢å¼ºæ•°é‡ï¼Œæ§åˆ¶åœ¨åˆç†èŒƒå›´
MAX_AUGMENTATION_COUNT = 200000  # çº¦å åŸæ•°æ®çš„27%

# æ¯ä¸ªç±»åˆ«çš„æœ€å¤§å¢å¼ºæ¯”ä¾‹ä¸Šé™
MAX_RATIO_PER_CLASS = 3.0  # ä»»ä½•ç±»åˆ«æœ€å¤šå¢å¼ºåˆ°åŸæ•°æ®çš„3å€

# GPUæ‰¹å¤„ç†å¤§å°
BATCH_SIZE = 32

def print_progress_header():
    """æ‰“å°å¸¦æœ‰é¢œè‰²çš„è¿›åº¦æ ‡é¢˜"""
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    GREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    
    print(f"\n{HEADER}{BOLD}{'=' * 65}{ENDC}")
    print(f"{BLUE}{BOLD}THUCNewsæ•°æ®é›†GPUåŠ é€Ÿå¢å¼ºå·¥å…· - æ•°æ®å¢å¼ºè¿›è¡Œä¸­{ENDC}")
    print(f"{HEADER}{BOLD}{'=' * 65}{ENDC}\n")

def create_progress_bar(total, desc, unit='it'):
    """åˆ›å»ºæ›´ä¸°å¯Œçš„è¿›åº¦æ¡"""
    return tqdm(
        total=total,
        desc=desc,
        unit=unit,
        bar_format='{l_bar}{bar:30}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]'
    )

def analyze_dataset(file_path, sample_limit=None):
    """
    åˆ†ææ•°æ®é›†åŸºæœ¬ä¿¡æ¯
    
    Args:
        file_path (str): æ•°æ®é›†æ–‡ä»¶è·¯å¾„
        sample_limit (int): æœ€å¤§æ ·æœ¬åˆ†ææ•°é‡ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨åˆ†æ
        
    Returns:
        tuple: (æ–‡æœ¬åˆ—è¡¨, æ ‡ç­¾åˆ—è¡¨, ç±»åˆ«è®¡æ•°, é•¿åº¦ç»Ÿè®¡)
    """
    texts = []
    labels = []
    label_counter = Counter()
    lengths = []
    
    print(f"æ­£åœ¨åŠ è½½å¹¶åˆ†ææ•°æ®é›†: {file_path}")
    
    # é¦–å…ˆè·å–æ–‡ä»¶æ€»è¡Œæ•°ç”¨äºè¿›åº¦æ¡
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            if sample_limit:
                total_lines = min(sum(1 for _ in f), sample_limit)
            else:
                total_lines = sum(1 for _ in f)
    except Exception as e:
        print(f"æ— æ³•è·å–æ–‡ä»¶è¡Œæ•°: {e}")
        total_lines = 0
    
    # ä½¿ç”¨æ›´ä¸°å¯Œçš„è¿›åº¦æ¡åŠ è½½æ•°æ®
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            progress_bar = create_progress_bar(total_lines, "ğŸ“‚ åŠ è½½æ•°æ®é›†", "è¡Œ")
            for i, line in enumerate(f):
                if sample_limit and i >= sample_limit:
                    break
                    
                line = line.strip()
                if not line:
                    continue
                
                # å‡è®¾æ ¼å¼æ˜¯"æ–‡æœ¬\tæ ‡ç­¾"
                parts = line.split('\t', 1)
                if len(parts) == 2:
                    text, label = parts
                    texts.append(text)
                    labels.append(label)
                    label_counter[label] += 1
                    lengths.append(len(text))
                
                progress_bar.update(1)
            
            progress_bar.close()
    except Exception as e:
        print(f"æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        return [], [], Counter(), []
    
    print(f"æ•°æ®é›†åˆ†æå®Œæˆ: å…±{len(texts)}æ¡æ ·æœ¬, {len(label_counter)}ä¸ªç±»åˆ«")
    
    # è®¡ç®—é•¿åº¦ç»Ÿè®¡
    length_stats = {
        "min": min(lengths) if lengths else 0,
        "max": max(lengths) if lengths else 0,
        "avg": sum(lengths) / len(lengths) if lengths else 0,
        "median": sorted(lengths)[len(lengths)//2] if lengths else 0,
        "percentiles": {
            "10": sorted(lengths)[int(len(lengths)*0.1)] if lengths else 0,
            "25": sorted(lengths)[int(len(lengths)*0.25)] if lengths else 0,
            "50": sorted(lengths)[int(len(lengths)*0.5)] if lengths else 0,
            "75": sorted(lengths)[int(len(lengths)*0.75)] if lengths else 0,
            "90": sorted(lengths)[int(len(lengths)*0.9)] if lengths else 0,
            "95": sorted(lengths)[int(len(lengths)*0.95)] if lengths else 0,
            "99": sorted(lengths)[int(len(lengths)*0.99)] if lengths else 0
        }
    }
    
    return texts, labels, label_counter, length_stats

def random_deletion(words, p=0.1):
    """
    éšæœºåˆ é™¤è¯è¯­
    
    Args:
        words (list): åˆ†è¯åçš„è¯è¯­åˆ—è¡¨
        p (float): åˆ é™¤æ¦‚ç‡
        
    Returns:
        list: å¤„ç†åçš„è¯è¯­åˆ—è¡¨
    """
    # å¦‚æœåªæœ‰ä¸€ä¸ªè¯ï¼Œè¿”å›åŸåˆ—è¡¨
    if len(words) == 1:
        return words
    
    # ä¿ç•™æ‰€æœ‰è¯çš„å‰¯æœ¬
    new_words = []
    
    for word in words:
        # ä»¥æ¦‚ç‡påˆ é™¤è¯
        r = random.uniform(0, 1)
        if r > p or word in STOPWORDS:
            new_words.append(word)
    
    # å¦‚æœåˆ é™¤äº†æ‰€æœ‰è¯ï¼Œéšæœºä¿ç•™ä¸€ä¸ª
    if len(new_words) == 0:
        rand_idx = random.randint(0, len(words)-1)
        new_words.append(words[rand_idx])
    
    return new_words

def random_swap(words, n=1):
    """
    éšæœºäº¤æ¢è¯è¯­ä½ç½®
    
    Args:
        words (list): åˆ†è¯åçš„è¯è¯­åˆ—è¡¨
        n (int): äº¤æ¢æ¬¡æ•°
        
    Returns:
        list: å¤„ç†åçš„è¯è¯­åˆ—è¡¨
    """
    # å¦‚æœè¯è¯­æ•°é‡å°‘äº2ï¼Œæ— æ³•äº¤æ¢
    if len(words) < 2:
        return words
    
    new_words = words.copy()
    
    for _ in range(n):
        # éšæœºé€‰æ‹©ä¸¤ä¸ªä½ç½®äº¤æ¢
        idx1, idx2 = random.sample(range(len(new_words)), 2)
        new_words[idx1], new_words[idx2] = new_words[idx2], new_words[idx1]
    
    return new_words

def chinese_eda(text, alpha_rd=0.1, alpha_rs=0.1):
    """
    ä¸­æ–‡ç‰ˆEDAæ•°æ®å¢å¼º (ä¸å«åŒä¹‰è¯æ›¿æ¢)
    
    Args:
        text (str): åŸå§‹æ–‡æœ¬
        alpha_rd (float): éšæœºåˆ é™¤æ¯”ä¾‹
        alpha_rs (float): éšæœºäº¤æ¢æ¯”ä¾‹
        
    Returns:
        list: å¢å¼ºåçš„æ–‡æœ¬åˆ—è¡¨
    """
    # åˆ†è¯
    words = list(jieba.cut(text))
    num_words = len(words)
    
    augmented_texts = []
    
    # éšæœºåˆ é™¤ (Random Deletion)
    if alpha_rd > 0:
        a_words = random_deletion(words, p=alpha_rd)
        augmented_texts.append(''.join(a_words))
    
    # éšæœºäº¤æ¢ (Random Swap)
    if alpha_rs > 0:
        n_rs = max(1, int(alpha_rs * num_words))
        a_words = random_swap(words, n=n_rs)
        augmented_texts.append(''.join(a_words))
    
    return augmented_texts

def load_translation_model(use_gpu=True):
    """
    åŠ è½½ç¿»è¯‘æ¨¡å‹ï¼ŒGPUåŠ é€Ÿ
    
    Args:
        use_gpu (bool): æ˜¯å¦ä½¿ç”¨GPU
        
    Returns:
        tuple: (tokenizer, model)
    """
    try:
        from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer
        
        # ä½¿ç”¨è¾ƒå°çš„å¤šè¯­è¨€ç¿»è¯‘æ¨¡å‹
        model_name = "facebook/m2m100_418M"
        
        print(f"æ­£åœ¨åŠ è½½ç¿»è¯‘æ¨¡å‹: {model_name}...")
        loading_bar = create_progress_bar(100, "ğŸ”„ åŠ è½½ç¿»è¯‘æ¨¡å‹")
        
        # æ¨¡æ‹ŸåŠ è½½è¿›åº¦
        for i in range(100):
            time.sleep(0.02)  # æ¨¡æ‹ŸåŠ è½½å»¶è¿Ÿ
            loading_bar.update(1)
        
        tokenizer = M2M100Tokenizer.from_pretrained(model_name)
        loading_bar.close()
        
        # åˆ›å»ºæ–°çš„è¿›åº¦æ¡ç”¨äºåŠ è½½æ¨¡å‹
        model_bar = create_progress_bar(100, "ğŸ“¦ åŠ è½½æ¨¡å‹æƒé‡")
        for i in range(100):
            time.sleep(0.03)  # æ¨¡æ‹ŸåŠ è½½å»¶è¿Ÿ
            model_bar.update(1)
        
        model = M2M100ForConditionalGeneration.from_pretrained(model_name)
        model_bar.close()
        
        # ç§»åŠ¨æ¨¡å‹åˆ°GPU
        if use_gpu and torch.cuda.is_available():
            gpu_bar = create_progress_bar(100, "ğŸš€ ç§»åŠ¨æ¨¡å‹åˆ°GPU")
            for i in range(100):
                time.sleep(0.01)
                gpu_bar.update(1)
            
            model = model.to('cuda')
            gpu_bar.close()
            print(f"âœ… æ¨¡å‹å·²åŠ è½½åˆ°GPU: {torch.cuda.get_device_name(0)}")
        else:
            print("âœ… æ¨¡å‹å·²åŠ è½½åˆ°CPU")
        
        return tokenizer, model
    
    except Exception as e:
        print(f"âŒ åŠ è½½ç¿»è¯‘æ¨¡å‹å¤±è´¥: {e}")
        return None, None

def back_translation_batch(texts, tokenizer, model, src_lang="zh", target_lang="en", batch_size=BATCH_SIZE):
    """
    æ‰¹é‡å›è¯‘å¢å¼ºï¼ŒGPUåŠ é€Ÿ
    
    Args:
        texts (list): æ–‡æœ¬åˆ—è¡¨
        tokenizer: åˆ†è¯å™¨
        model: æ¨¡å‹
        src_lang (str): æºè¯­è¨€ä»£ç 
        target_lang (str): ç›®æ ‡è¯­è¨€ä»£ç 
        batch_size (int): æ‰¹å¤„ç†å¤§å°
        
    Returns:
        list: å›è¯‘åçš„æ–‡æœ¬åˆ—è¡¨
    """
    if not texts or tokenizer is None or model is None:
        return []
    
    result_texts = []
    use_gpu = torch.cuda.is_available() and next(model.parameters()).is_cuda
    device = 'cuda' if use_gpu else 'cpu'
    
    # åˆ›å»ºæ€»ä½“è¿›åº¦æ¡
    total_batches = (len(texts) + batch_size - 1) // batch_size
    main_bar = create_progress_bar(total_batches, "ğŸ”„ æ‰¹é‡å›è¯‘å¤„ç†", "æ‰¹æ¬¡")
    
    # æ‰¹é‡å¤„ç†
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i+batch_size]
        batch_index = i // batch_size + 1
        
        try:
            # æ›´æ–°ä¸»è¿›åº¦æ¡æè¿°ï¼Œæ˜¾ç¤ºå½“å‰å¤„ç†çš„æ‰¹æ¬¡
            main_bar.set_description(f"ğŸ”„ æ‰¹é‡å›è¯‘ [{batch_index}/{total_batches}]")
            
            # ä¸­æ–‡åˆ°è‹±æ–‡
            tokenizer.src_lang = src_lang
            encoded_zh = tokenizer(batch_texts, return_tensors="pt", padding=True, truncation=True, max_length=128)
            
            # ç§»åŠ¨åˆ°GPU
            if use_gpu:
                encoded_zh = {k: v.to(device) for k, v in encoded_zh.items()}
            
            with torch.no_grad():
                generated_tokens = model.generate(
                    **encoded_zh,
                    forced_bos_token_id=tokenizer.get_lang_id(target_lang),
                    max_length=128
                )
            
            en_texts = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
            
            # è‹±æ–‡å›è¯‘åˆ°ä¸­æ–‡
            tokenizer.src_lang = target_lang
            encoded_en = tokenizer(en_texts, return_tensors="pt", padding=True, truncation=True, max_length=128)
            
            # ç§»åŠ¨åˆ°GPU
            if use_gpu:
                encoded_en = {k: v.to(device) for k, v in encoded_en.items()}
            
            with torch.no_grad():
                generated_tokens = model.generate(
                    **encoded_en,
                    forced_bos_token_id=tokenizer.get_lang_id(src_lang),
                    max_length=128
                )
            
            back_translated = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
            result_texts.extend(back_translated)
            
            # æ›´æ–°è¿›åº¦æ¡
            main_bar.update(1)
            main_bar.set_postfix({"å®Œæˆ": f"{min(i + batch_size, len(texts))}/{len(texts)}"})
            
        except Exception as e:
            print(f"æ‰¹å¤„ç†å›è¯‘å¤±è´¥: {e}")
            # å‡ºé”™æ—¶å¡«å……åŸæ–‡
            result_texts.extend(batch_texts)
            main_bar.update(1)
    
    main_bar.close()
    print(f"âœ… æ‰¹é‡å›è¯‘å¤„ç†å®Œæˆï¼Œå…±å¤„ç†{len(texts)}æ¡æ–‡æœ¬")
    
    return result_texts

def eda_worker(args):
    """
    å¤šè¿›ç¨‹å·¥ä½œå‡½æ•°ï¼Œå¤„ç†EDAå¢å¼º
    
    Args:
        args (tuple): (æ–‡æœ¬, æ ‡ç­¾, ä»»åŠ¡ID)
        
    Returns:
        list: å¢å¼ºåçš„(æ–‡æœ¬, æ ‡ç­¾)åˆ—è¡¨
    """
    text, label, task_id = args
    results = []
    
    try:
        # EDAå¢å¼º
        aug_texts = chinese_eda(text, alpha_rd=0.1, alpha_rs=0.1)
        for aug_text in aug_texts:
            if aug_text and aug_text != text:
                results.append((aug_text, label))
    
    except Exception as e:
        pass  # å®‰é™å¤„ç†é”™è¯¯ï¼Œé¿å…è¿›åº¦æ¡æ··ä¹±
    
    return results

def choose_method_by_length(text_length):
    """
    æ ¹æ®æ–‡æœ¬é•¿åº¦é€‰æ‹©åˆé€‚çš„å¢å¼ºæ–¹æ³•
    
    Args:
        text_length (int): æ–‡æœ¬é•¿åº¦
        
    Returns:
        str: å¢å¼ºæ–¹æ³•åç§° ("back_translation" æˆ– "eda")
    """
    if text_length < 10:  # éå¸¸çŸ­çš„æ–‡æœ¬
        return "back_translation"  # å›è¯‘æ¯”è¾ƒé€‚åˆçŸ­æ–‡æœ¬
    elif text_length < 20:  # ä¸­ç­‰é•¿åº¦
        return random.choice(["back_translation", "eda"])  # éšæœºé€‰æ‹©
    else:  # è¾ƒé•¿æ–‡æœ¬
        return "eda"  # EDAæ–¹æ³•æ›´é€‚åˆé•¿æ–‡æœ¬

def calculate_augmentation_targets(label_counter, enhancement_ratios=None, max_count=MAX_AUGMENTATION_COUNT):
    """
    è®¡ç®—æ¯ä¸ªç±»åˆ«åº”è¯¥å¢å¼ºçš„æ ·æœ¬æ•°é‡
    
    Args:
        label_counter (Counter): å„ç±»åˆ«æ ·æœ¬è®¡æ•°
        enhancement_ratios (dict): å„ç±»åˆ«å¢å¼ºæ¯”ä¾‹é…ç½®
        max_count (int): æœ€å¤§å¢å¼ºæ•°é‡
        
    Returns:
        dict: æ¯ä¸ªç±»åˆ«åº”è¯¥å¢å¼ºçš„æ ·æœ¬æ•°é‡
    """
    if enhancement_ratios is None:
        enhancement_ratios = DEFAULT_ENHANCEMENT_RATIOS
    
    # ç¡®ä¿æ‰€æœ‰ç±»åˆ«éƒ½æœ‰å¢å¼ºæ¯”ä¾‹é…ç½®
    for label in label_counter:
        if label not in enhancement_ratios:
            # å¯¹äºæœªé…ç½®çš„ç±»åˆ«ï¼Œä½¿ç”¨é»˜è®¤æ¯”ä¾‹0.2
            enhancement_ratios[label] = 0.2
    
    # è®¡ç®—æ¯ä¸ªç±»åˆ«åº”å¢å¼ºçš„æ•°é‡
    augmentation_targets = {}
    total_augmentation = 0
    
    # åˆ›å»ºè®¡ç®—è¿›åº¦æ¡
    calc_bar = create_progress_bar(len(label_counter), "ğŸ“Š è®¡ç®—å¢å¼ºç›®æ ‡")
    
    for label, count in label_counter.items():
        ratio = min(enhancement_ratios.get(label, 0.2), MAX_RATIO_PER_CLASS)
        target_count = int(count * ratio)
        augmentation_targets[label] = target_count
        total_augmentation += target_count
        calc_bar.update(1)
    
    calc_bar.close()
    
    # å¦‚æœæ€»å¢å¼ºæ•°é‡è¶…è¿‡ä¸Šé™ï¼ŒæŒ‰æ¯”ä¾‹ç¼©å‡
    if total_augmentation > max_count:
        scale_bar = create_progress_bar(len(augmentation_targets), "âš–ï¸ è°ƒæ•´å¢å¼ºæ¯”ä¾‹")
        scale_factor = max_count / total_augmentation
        for label in augmentation_targets:
            augmentation_targets[label] = int(augmentation_targets[label] * scale_factor)
            scale_bar.update(1)
        scale_bar.close()
    
    return augmentation_targets

def print_colored_stats(label_counter, augmentation_targets):
    """æ‰“å°å½©è‰²çš„ç»Ÿè®¡ä¿¡æ¯"""
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    
    print(f"\n{HEADER}{BOLD}=== å¢å¼ºç›®æ ‡ ==={ENDC}")
    total_target = sum(augmentation_targets.values())
    
    # æŒ‰ç›®æ ‡æ•°é‡æ’åº
    sorted_targets = sorted(augmentation_targets.items(), key=lambda x: x[1], reverse=True)
    
    for label, target in sorted_targets:
        original = label_counter[label]
        if target > 0:
            ratio = target / original * 100
            color = RED if ratio > 100 else YELLOW if ratio > 50 else GREEN
            print(f"  ç±»åˆ« {BLUE}{label}{ENDC}: {original} â†’ {BOLD}{original + target}{ENDC} (+{color}{target}{ENDC}, +{color}{ratio:.2f}%{ENDC})")
    
    print(f"{BOLD}æ€»å¢å¼ºæ•°é‡: {GREEN}{total_target}{ENDC}")

def gpu_optimized_augment(file_path, output_path=None, enhancement_ratios=None, 
                        max_augmentation=MAX_AUGMENTATION_COUNT, 
                        num_workers=4, use_gpu=True, sample_limit=None):
    """
    å¯¹æ•°æ®é›†è¿›è¡ŒGPUåŠ é€Ÿçš„å¹³è¡¡å¢å¼º
    
    Args:
        file_path (str): æ•°æ®é›†æ–‡ä»¶è·¯å¾„
        output_path (str): è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›å¢å¼ºåçš„æ•°æ®
        enhancement_ratios (dict): å„ç±»åˆ«å¢å¼ºæ¯”ä¾‹é…ç½®
        max_augmentation (int): æœ€å¤§å¢å¼ºæ•°é‡
        num_workers (int): å¹¶è¡Œå¤„ç†çš„å·¥ä½œè¿›ç¨‹æ•°
        use_gpu (bool): æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿ
        sample_limit (int): å¤„ç†çš„æœ€å¤§æ ·æœ¬æ•°ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨å¤„ç†
        
    Returns:
        tuple or None: å¦‚æœoutput_pathä¸ºNoneï¼Œè¿”å›(å¢å¼ºåçš„æ–‡æœ¬åˆ—è¡¨, æ ‡ç­¾åˆ—è¡¨)ï¼›å¦åˆ™è¿”å›None
    """
    # æ‰“å°å½©è‰²è¿›åº¦æ ‡é¢˜
    print_progress_header()
    
    # åˆ†ææ•°æ®é›†
    texts, labels, label_counter, length_stats = analyze_dataset(file_path, sample_limit)
    
    if not texts:
        print("âŒ æ•°æ®é›†ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œå¢å¼º")
        return [], []
    
    # æ‰“å°æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    
    print(f"\n{HEADER}{BOLD}=== æ•°æ®é›†åŸºæœ¬ç»Ÿè®¡ ==={ENDC}")
    print(f"{BOLD}æ€»æ ·æœ¬æ•°: {GREEN}{len(texts)}{ENDC}")
    
    print(f"\n{BOLD}ç±»åˆ«åˆ†å¸ƒ:{ENDC}")
    total_samples = sum(label_counter.values())
    # æŒ‰æ•°é‡æ’åº
    sorted_labels = sorted(label_counter.items(), key=lambda x: x[1], reverse=True)
    for label, count in sorted_labels:
        ratio = count/total_samples*100
        color = GREEN if ratio > 10 else YELLOW if ratio > 5 else RED
        print(f"  ç±»åˆ« {BLUE}{label}{ENDC}: {count} ({color}{ratio:.2f}%{ENDC})")
    
    print(f"\n{BOLD}æ–‡æœ¬é•¿åº¦ç»Ÿè®¡:{ENDC}")
    print(f"  æœ€å°é•¿åº¦: {length_stats['min']}")
    print(f"  æœ€å¤§é•¿åº¦: {length_stats['max']}")
    print(f"  å¹³å‡é•¿åº¦: {GREEN}{length_stats['avg']:.2f}{ENDC}")
    print(f"  ä¸­ä½æ•°é•¿åº¦: {GREEN}{length_stats['median']}{ENDC}")
    
    print(f"\n{BOLD}æ–‡æœ¬é•¿åº¦ç™¾åˆ†ä½ç‚¹:{ENDC}")
    for p, v in length_stats['percentiles'].items():
        print(f"  {p}%: {v}")
    
    # è®¡ç®—æ¯ä¸ªç±»åˆ«åº”å¢å¼ºçš„æ ·æœ¬æ•°é‡
    augmentation_targets = calculate_augmentation_targets(
        label_counter, enhancement_ratios, max_augmentation
    )
    
    # æ‰“å°å½©è‰²å¢å¼ºç›®æ ‡ä¿¡æ¯
    print_colored_stats(label_counter, augmentation_targets)
    
    # å¦‚æœæ²¡æœ‰éœ€è¦å¢å¼ºçš„æ ·æœ¬ï¼Œç›´æ¥è¿”å›åŸå§‹æ•°æ®æˆ–å†™å…¥åŸå§‹æ•°æ®
    if sum(augmentation_targets.values()) == 0:
        print(f"\n{YELLOW}æ²¡æœ‰éœ€è¦å¢å¼ºçš„æ ·æœ¬ï¼Œä¿æŒåŸå§‹æ•°æ®{ENDC}")
        if output_path:
            print(f"{BLUE}æ­£åœ¨å°†åŸå§‹æ•°æ®å†™å…¥ {output_path}...{ENDC}")
            with open(output_path, 'w', encoding='utf-8') as f:
                write_bar = create_progress_bar(len(texts), "ğŸ“ å†™å…¥åŸå§‹æ•°æ®", "è¡Œ")
                for text, label in zip(texts, labels):
                    f.write(f"{text}\t{label}\n")
                    write_bar.update(1)
                write_bar.close()
            print(f"{GREEN}âœ… åŸå§‹æ•°æ®å·²ä¿å­˜åˆ° {output_path}{ENDC}")
            return None
        else:
            return texts, labels
    
    # æŒ‰ç±»åˆ«ç»„ç»‡æ•°æ®
    data_by_label = defaultdict(list)
    org_bar = create_progress_bar(len(texts), "ğŸ”„ ç»„ç»‡æ•°æ®", "æ ·æœ¬")
    for text, label in zip(texts, labels):
        data_by_label[label].append(text)
        org_bar.update(1)
    org_bar.close()
    
    # å‡†å¤‡å¢å¼ºä»»åŠ¡ï¼ŒæŒ‰æ–¹æ³•åˆ†ç»„
    eda_tasks = []
    back_translation_texts = []
    back_translation_labels = []
    
    # ä¸ºæ¯ä¸ªæ ‡ç­¾å‡†å¤‡å¢å¼ºä»»åŠ¡
    prep_bar = create_progress_bar(len(augmentation_targets), "ğŸ”§ å‡†å¤‡å¢å¼ºä»»åŠ¡", "ç±»åˆ«")
    
    # ä¸ºæ¯ä¸ªæ ‡ç­¾å‡†å¤‡å¢å¼ºä»»åŠ¡
    for label, target in augmentation_targets.items():
        if target <= 0 or label not in data_by_label:
            prep_bar.update(1)
            continue
        
        # è·å–è¯¥æ ‡ç­¾çš„æ–‡æœ¬
        source_texts = data_by_label[label]
        
        # è®¡ç®—æ¯ä¸ªæ–¹æ³•çš„æ•°é‡
        # EDAæ–¹æ³•é€šå¸¸èƒ½äº§ç”Ÿæ›´å¤šçš„å˜ä½“
        bt_ratio = 0.4  # å›è¯‘æ¯”ä¾‹
        eda_ratio = 0.6  # EDAæ¯”ä¾‹
        
        # è®¡ç®—æ¯ç§æ–¹æ³•çš„ä»»åŠ¡æ•°
        bt_count = int(target * bt_ratio)
        eda_count = target - bt_count
        
        # å‡†å¤‡å›è¯‘ä»»åŠ¡
        if bt_count > 0:
            bt_indices = random.sample(range(len(source_texts)), min(bt_count, len(source_texts)))
            for idx in bt_indices:
                back_translation_texts.append(source_texts[idx])
                back_translation_labels.append(label)
        
        # å‡†å¤‡EDAä»»åŠ¡
        if eda_count > 0:
            # è€ƒè™‘EDAä¼šç”Ÿæˆå¤šä¸ªå˜ä½“ï¼Œå‡å°‘ä»»åŠ¡æ•°
            eda_task_count = min(eda_count, len(source_texts))
            eda_indices = random.sample(range(len(source_texts)), eda_task_count)
            for i, idx in enumerate(eda_indices):
                eda_tasks.append((source_texts[idx], label, i))
        
        # æ›´æ–°è¿›åº¦æ¡
        prep_bar.update(1)
    
    prep_bar.close()
    
    # æ‰“ä¹±ä»»åŠ¡é¡ºåº
    random.shuffle(eda_tasks)
    combined_bt = list(zip(back_translation_texts, back_translation_labels))
    random.shuffle(combined_bt)
    back_translation_texts, back_translation_labels = zip(*combined_bt) if combined_bt else ([], [])
    
    print(f"\n{BLUE}å‡†å¤‡æ‰§è¡Œå›è¯‘ä»»åŠ¡: {len(back_translation_texts)}ä¸ª{ENDC}")
    print(f"{BLUE}å‡†å¤‡æ‰§è¡ŒEDAä»»åŠ¡: {len(eda_tasks)}ä¸ª{ENDC}\n")
    
    # åˆå§‹åŒ–å¢å¼ºç»“æœ
    augmented_data = []
    
    # æ‰§è¡Œå›è¯‘ä»»åŠ¡ï¼ˆGPUåŠ é€Ÿï¼‰
    if back_translation_texts:
        print(f"{HEADER}{BOLD}=== æ‰§è¡Œå›è¯‘å¢å¼º ==={ENDC}")
        
        # åŠ è½½ç¿»è¯‘æ¨¡å‹
        tokenizer, model = load_translation_model(use_gpu=use_gpu)
        
        if tokenizer and model:
            # æ‰¹é‡æ‰§è¡Œå›è¯‘
            start_time = time.time()
            augmented_texts = back_translation_batch(
                list(back_translation_texts), tokenizer, model, 
                batch_size=BATCH_SIZE
            )
            end_time = time.time()
            
            print(f"{GREEN}å›è¯‘å¢å¼ºå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’{ENDC}")
            
            # è¿‡æ»¤æœ‰æ•ˆçš„å¢å¼ºç»“æœ
            filter_bar = create_progress_bar(len(augmented_texts), "ğŸ” è¿‡æ»¤æœ‰æ•ˆç»“æœ", "æ ·æœ¬")
            valid_count = 0
            
            for aug_text, orig_text, label in zip(augmented_texts, back_translation_texts, back_translation_labels):
                if aug_text and aug_text != orig_text:
                    augmented_data.append((aug_text, label))
                    valid_count += 1
                filter_bar.update(1)
            
            filter_bar.close()
            print(f"{GREEN}æœ‰æ•ˆå›è¯‘å¢å¼ºç»“æœ: {valid_count}ä¸ª ({valid_count/len(augmented_texts)*100:.2f}%){ENDC}")
        else:
            print(f"{RED}å›è¯‘æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè·³è¿‡å›è¯‘å¢å¼º{ENDC}")
    
    # æ‰§è¡ŒEDAä»»åŠ¡ï¼ˆå¤šè¿›ç¨‹ï¼‰
    if eda_tasks:
        print(f"\n{HEADER}{BOLD}=== æ‰§è¡ŒEDAå¢å¼º ==={ENDC}")
        
        # å¯åŠ¨å¤šè¿›ç¨‹å¤„ç†
        if num_workers > 1:
            print(f"{BLUE}ä½¿ç”¨{num_workers}ä¸ªå·¥ä½œè¿›ç¨‹å¹¶è¡Œå¤„ç†EDAä»»åŠ¡{ENDC}")
            with multiprocessing.Pool(processes=num_workers) as pool:
                eda_bar = create_progress_bar(len(eda_tasks), "ğŸ”„ EDAå¢å¼º", "ä»»åŠ¡")
                
                # ä½¿ç”¨imapæ‰¹é‡å¤„ç†ï¼Œæ›´æ–°è¿›åº¦æ¡
                results_iter = pool.imap(eda_worker, eda_tasks, chunksize=10)
                
                # å¤„ç†ç»“æœå¹¶æ›´æ–°è¿›åº¦æ¡
                for result in results_iter:
                    augmented_data.extend(result)
                    eda_bar.update(1)
                
                eda_bar.close()
        else:
            # å•è¿›ç¨‹å¤„ç†
            eda_bar = create_progress_bar(len(eda_tasks), "ğŸ”„ EDAå¢å¼º (å•è¿›ç¨‹)", "ä»»åŠ¡")
            for task in eda_tasks:
                result = eda_worker(task)
                augmented_data.extend(result)
                eda_bar.update(1)
            eda_bar.close()
        
        # è®¡ç®—EDAå¢å¼ºç»“æœæ•°é‡
        eda_results = len([d for d in augmented_data if d[1] not in back_translation_labels]) \
                    if back_translation_labels else len(augmented_data)
        print(f"{GREEN}EDAå¢å¼ºå®Œæˆï¼Œç”Ÿæˆ: {eda_results}ä¸ªç»“æœ{ENDC}")
    
    # æ•´åˆåŸå§‹æ•°æ®å’Œå¢å¼ºæ•°æ®
    augmented_texts, augmented_labels = [], []
    
    # å…ˆæ·»åŠ åŸå§‹æ•°æ®
    print(f"\n{BLUE}æ­£åœ¨æ•´åˆåŸå§‹æ•°æ®å’Œå¢å¼ºæ•°æ®...{ENDC}")
    merge_bar = create_progress_bar(len(texts) + len(augmented_data), "ğŸ”„ æ•´åˆæ•°æ®", "æ ·æœ¬")
    
    # æ·»åŠ åŸå§‹æ•°æ®
    for text, label in zip(texts, labels):
        augmented_texts.append(text)
        augmented_labels.append(label)
        merge_bar.update(1)
    
    # æ·»åŠ å¢å¼ºæ•°æ®
    for text, label in augmented_data:
        augmented_texts.append(text)
        augmented_labels.append(label)
        merge_bar.update(1)
    
    merge_bar.close()
    
    # è®¡ç®—å¢å¼ºåçš„ç±»åˆ«åˆ†å¸ƒ
    final_label_counter = Counter(augmented_labels)
    
    print(f"\n{HEADER}{BOLD}=== å¢å¼ºç»“æœ ==={ENDC}")
    print(f"{BOLD}åŸå§‹æ•°æ®é‡: {len(texts)}{ENDC}")
    print(f"{BOLD}å¢å¼ºäº§ç”Ÿæ ·æœ¬: {GREEN}{len(augmented_data)}{ENDC}")
    print(f"{BOLD}æœ€ç»ˆæ•°æ®é‡: {GREEN}{len(augmented_texts)}{ENDC}")
    print(f"{BOLD}å¢å¼ºæ¯”ä¾‹: {GREEN}{len(augmented_data)/len(texts)*100:.2f}%{ENDC}")
    
    print(f"\n{BOLD}å¢å¼ºåç±»åˆ«åˆ†å¸ƒ:{ENDC}")
    total_final = sum(final_label_counter.values())
    
    # æŒ‰ç…§å¢å¼ºåçš„æ•°é‡æ’åº
    sorted_final = sorted(final_label_counter.items(), key=lambda x: x[1], reverse=True)
    
    for label, count in sorted_final:
        original = label_counter[label]
        increase = count - original
        ratio_before = original / sum(label_counter.values()) * 100
        ratio_after = count / total_final * 100
        
        if increase > 0:
            print(f"  ç±»åˆ« {BLUE}{label}{ENDC}: {original} ({YELLOW}{ratio_before:.2f}%{ENDC}) â†’ {GREEN}{count}{ENDC} ({GREEN}{ratio_after:.2f}%{ENDC}) (+{increase}, +{increase/original*100:.2f}%)")
        else:
            print(f"  ç±»åˆ« {BLUE}{label}{ENDC}: {count} ({ratio_after:.2f}%) (æœªå¢å¼º)")
    
    # å†™å…¥æ–‡ä»¶æˆ–è¿”å›ç»“æœ
    if output_path:
        print(f"\n{BLUE}æ­£åœ¨å°†å¢å¼ºåçš„æ•°æ®å†™å…¥ {output_path}...{ENDC}")
        with open(output_path, 'w', encoding='utf-8') as f:
            write_bar = create_progress_bar(len(augmented_texts), "ğŸ’¾ ä¿å­˜å¢å¼ºæ•°æ®", "è¡Œ")
            for text, label in zip(augmented_texts, augmented_labels):
                f.write(f"{text}\t{label}\n")
                write_bar.update(1)
            write_bar.close()
        print(f"{GREEN}âœ… å¢å¼ºæ•°æ®å·²ä¿å­˜åˆ° {output_path}{ENDC}")
        return None
    else:
        return augmented_texts, augmented_labels

def main():
    """ä¸»å‡½æ•°ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶æ‰§è¡Œæ•°æ®å¢å¼º"""
    import argparse
    
    parser = argparse.ArgumentParser(description="THUCNewsæ•°æ®é›†GPUåŠ é€Ÿå¹³è¡¡å¢å¼ºå·¥å…·")
    parser.add_argument("--input", "-i", type=str, required=True, help="è¾“å…¥æ•°æ®é›†æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", "-o", type=str, default=None, help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--workers", "-w", type=int, default=4, help="å¹¶è¡Œå¤„ç†çš„å·¥ä½œè¿›ç¨‹æ•°")
    parser.add_argument("--max", "-m", type=int, default=MAX_AUGMENTATION_COUNT, help="æœ€å¤§å¢å¼ºæ•°é‡")
    parser.add_argument("--no-gpu", action="store_true", help="ä¸ä½¿ç”¨GPUåŠ é€Ÿ")
    parser.add_argument("--sample", "-s", type=int, default=None, help="å¤„ç†çš„æœ€å¤§æ ·æœ¬æ•°")
    
    args = parser.parse_args()
    
    # æ‰§è¡Œæ•°æ®å¢å¼º
    gpu_optimized_augment(
        file_path=args.input,
        output_path=args.output,
        max_augmentation=args.max,
        num_workers=args.workers,
        use_gpu=not args.no_gpu,
        sample_limit=args.sample
    )

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\033[91må¤„ç†è¢«ç”¨æˆ·ä¸­æ–­\033[0m")
    except Exception as e:
        print(f"\n\033[91må¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}\033[0m")
    finally:
        print("\n\033[92mç¨‹åºç»“æŸ\033[0m")